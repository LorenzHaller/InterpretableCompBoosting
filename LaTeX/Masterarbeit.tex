\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}


\title{Master Thesis}
\author{Lorenz Haller}
\date{September 2019}


% \maketitle

 
 \begin{document}

 %-----------------------------------------------------------------
 % Titel
 %-----------------------------------------------------------------
 
\begin{center}
\vspace*{0.5cm}
{\Huge \bf Gradually }\\
\vspace*{0.3cm}
{\Huge \bf interpretable models}\\
\vspace*{0.3cm}
{\Huge \bf via }\\
\vspace*{0.3cm}
{\Huge \bf component-wise boosting} \\
\vspace*{1cm}
{\Huge Master Thesis} \\
\vspace*{1cm}

\begin{figure}[htp]
    \centering
    \includegraphics[width=6cm]{LMU-siegel.png}
\end{figure}

\end{center}
\vspace*{2cm}

\begin{tabular}{ll}
Verfasser:  &Lorenz Haller \\
Betreuer: & Christoph Molnar / Prof. Dr. Bernd Bischl\\
Datum:			& \today \\
\end{tabular}

\newpage

\begin{abstract}
\section*{Abstract}

A problem in model selection is the big gap between models that have high interpretability and models that have high prediction accuracy. When selecting a model, you have to choose between a simple model that can be interpreted well but has limited accuracy like a linear model or a decision tree, and models that have high prediction accuracy but are hardly interpretable like random forests or SVMs. This master thesis tries to develop a framework between those two extreme cases that contains a reasonable tradeoff between interpretability and accuracy.

The idea shall be embedded in the framework of componentwise boosting.
The approach is to create different model categories and in each “step” models from that category are used and boosted until no further improvement is made (defined by a stop criterium). Then models from the second category are allowed and so on.
First category models could be sparse linear models or decision trees / tree stumps. For the next category more features, interactions or non linear elements like splines could be allowed. Subsequently, more complex learners like deeper trees or random forests can be boosted. ??
The resulting model would have an additive form like y = g(x) + g2(x) + … + e, where g(x), g2(x) etc. represent the a function from one model category.

The objective is to quantify how much each model contributes to the predictions, on a average as well as on an individual level. Here, the gain through every additional step shall be quantified.
Furthermore, the model should have the ability to identify different areas (described by feature rules) in the data set. For some areas, interpretable models will be sufficient, whereas for other areas only more complex models will lead to high prediction accuracy. Here, an additional model could be fitted which tries to explain when simple models are sufficient and when more complex models are needed.
Finally some sort of reporting tool for the approach shall be developed which for a given data set describes the contributions of the individual model parts, identifies areas in the data set where more complex models need to be applied and gives some interpretations.

In the end the approach shall be tested on data examples. For some example data sets, the benefits of using this approach shall be shown, also in comparison to other approaches. Also a benchmark comparison could be done to compare the model on a more quantitative level.


\end{abstract}

\newpage

\section{Introduction}

A company from the Telecommunications sector authorizes a consulting company to help them increase their sales. They want to identify those customers, which are most likely to buy their product if they are contacted by phone.  The consulting company uses data from the customers and from previous calls to build a model to predict which customers have the highest likelihood to buy a product after being called. Let’s say they use an XGBoost or RandomForest model and get satisfying values for accuracy and AUC. The consulting company is able to deliver a list of the most promising customers, which should be contacted by employees of the Telecommunications company. \\
However, an aspect that is quite crucial for the success of the calls is not only whom to call but also to information why a specific person is contacted now to incorporate these details in the call. Those insights can be the position and decision-making power of a customer in his company as well as recent activity on the Tec company’s web page and certain product pages. These data are quite important for the success of the call. \\
In order to be able do deliver these data the consulting company must not use a model that is only focuses on accuracy but also on interpretability in order to find out which of a customer’s features are essential for the prediction of the model and can be used to increase the probability of success for the call.
This example was a first illustration why interpretability always has to be considered next to accuracy when working with machine learning methods. 
While interpretability is getting more and more attention, there is still a big “gap” between prediction accuracy and interpretability. It often seems that only those two extremes are possible: either using high performing methods like Random Forests or Boosting but mainly waving interpretability or using clearly worse performing methods like simple linear models which on the other hand can be interpreted well. \\
The new approach in this thesis tries to minor reduce this gap by combining prediction accuracy and interpretability.


\end{document}
